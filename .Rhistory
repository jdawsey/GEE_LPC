bestEffort = TRUE,
tileScale = 16
)
stddevs <- ee$Image$constant(stdDevDict$values(st_bandNames))
standardized <- centered$divide(stddevs)
visParam_st <- list(bands <- c('N', 'R', 'G'),
min = -1,
max = 2,
gamma = 1.2
)
#Map$addLayer(standardized, visParams = visParam_st)
rgb_savi <- function(image_given) {
image_bands <- image_given$select(c("R", "N"))
image <- image_bands
savi <- image$expression(
expression = '(1 + 0.6) * (N - R) / (N + R + 0.6)',
opt_map =  list(
'R' = image$select('R'),
'N' = image$select('N')
)
)$rename('savi')
return(savi)
}
savi <- rgb_savi(standardized)
#Map$addLayer(savi)
# adding savi as a band to use
standardized <- standardized$addBands(savi)
# checking was added
#band_names <- standardized$bandNames()
#print(band_names$get(4)$getInfo())
rgb_endvi <- function(image_given) {
image_bands <- image_given$select(c("N", "G", "B"))
image <- image_bands
endvi <- image$expression(
expression = '((N + G) - (2 * B)) / ((N + G) + (2 + B))',
opt_map =  list(
'N' = image$select('N'),
'G' = image$select('G'),
'B' = image$select('B')
)
)$rename('endvi')
return(endvi)
}
endvi <- rgb_endvi(standardized)
# adding endvi as a band to use
standardized <- standardized$addBands(endvi)
# checking was added
band_names <- standardized$bandNames()
#print(band_names$get(5)$getInfo())
### DoG sharpening
fat <- ee$Kernel$gaussian(
radius = 3,
sigma = 3,
magnitude = -1.0,
units = 'pixels'
)
skinny <- ee$Kernel$gaussian(
radius = 3,
sigma = 0.5,
units = 'pixels'
)
dog <- fat$add(skinny)
gauss <- standardized$add(standardized$convolve(dog)) #changed name from sharpened
### gaussian smoothing
#gaussianKernel <- ee$Kernel$gaussian(
#  radius = 3,
#  units = 'pixels'
#)
#gauss <- sharpened$convolve(gaussianKernel)
#visParamGauss <- list(bands <- c('R', 'G', 'B'),
#  min= 0,
#  max= 255
#  )
### checking that image was smoothed
#Map$addLayer(gauss, visParams = visParamGauss)
### creating training samples for the unsupervised classification
training <- gauss$sample(
region = shp,
scale = 1, #change depending on year
numPixels = 10000
)
###
### the actual classification function
clusterer <- ee$Clusterer$wekaXMeans(maxClusters = 10, maxIterations = 5, useKD = TRUE) %>% # change clusters depending on imagery ### check accuracies
ee$Clusterer$train(training)
result <- gauss$cluster(clusterer)
###
### creating a landcover palette to view the result
landcoverPalette <- c(
'#00a944',
'#d6d6d6',
'#c65b8d',
'#000000',
'#ff3434',
'#5bb48f',
'#47f37c',
'#c04848',
'#ded132',
'#5bb48f',
'#0f0077',
'#778bff',
'#8f8f8f',
'#000000',
'#d9a300'
)
visPalette <- list(
min= 0,
max= 9, # change depending on number of clusters
palette = landcoverPalette
)
###
### adding maps to compare
#classified <- Map$addLayer(result, visParams = visPalette)
#imageryMap <- Map$addLayer(standardized, visParams= visParam_st)
###
drive_image <- ee_image_to_drive(
image = gauss,
description = "export",
folder = "!imagery",
region = shp,
scale = 1,
max = 130000000
)
drive_image$start()
#shp_geo <- shp$geometry()
drive_image <- ee_image_to_drive(
image = result,
description = "export",
folder = "!imagery",
region = shp,
scale = 1,
max = 130000000
)
drive_image$start()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(stats)
library(car)
library(caret)
library(MASS)
library(pscl)
library(aod)
mesq_pts_manus <- read.csv('D:/!!Research/rgee_test/GEE_LPC/point_data/draft_points_drops_manu.csv',
header = TRUE)
mesq_pts_manus <- read.csv('D:/!!Research/rgee_test/GEE_LPC/point_data/draft_points_drops_manus.csv',
header = TRUE)
fit_graph <- glm(mesq_pres ~ ann_precip
+ b3_carbonCont_30 + b3_soilWater_30 + b1_clayCont_0,
data = mesq_pts_manus,family=binomial())
fit_graph <- glm(mesquite_presence ~ annual_precip
+ CarbonContent_30cm + SoilWater_30cm + ClayContent_0cm,
data = mesq_pts_manus,family=binomial())
summary(fit_graph)
probabilities <- predict(fit_graph, type = "response")
pred_class <- ifelse(probabilities > 0.5, "pos", "neg")
predictors <- colnames(mesq_pts_manus)
mydata <- mesq_pts_manus %>%
mutate(logit = log(probabilities/(1 - probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
## a)
val_matrix_a <- c(1, -1, 2, 5, 3, 0, 5, 6, 2)
a <- matrix(val_matrix_a, ncol = 3)
## print(a) -- checking for correctness
## b)
val_matrix_b <- c(2, 1, 2, -3, 0, 3, 5, 6, 1)
b <- matrix(val_matrix_b, ncol = 3)
## print(b)
## c)
val_matrix_c <- c(5, 4, 3, 1, 0, -1, 9, 6, 2, 0, -2, 4)
c <- matrix(val_matrix_c, ncol = 4)
## print(c)
## d)
val_matrix_d <- c(3, 4, 0, -2, 2, 1, 2, 5, 5, 3, 1, 6)
d <- matrix(val_matrix_d, ncol = 3)
## print(d)
## a)
a + b
## b)
a - 2*b
## c)
(a - 2)*b
[,1] [,2] [,3]
## d)
a^2
## e)
sqrt(a)
## f)
t(c)
?t
## g)
c + d
## h)
t(c) + d
## i)
c %*% d
?%*%
?'%*%'
## j)
a - 2 * diag(1, 3)
?diag()
2*diag(1, 3)
diag(1, 3)
## k)
matrix(1, 3, 3)
## k)
## matrix(1, 3, 3)
a - matrix(1, 3, 3)
## l)
dim(a)
## a)
a[1,]
## b)
b[,2]
## c)
rbind(a, b)
## c)
?rbind()
## d)
cbind(a, b)
## e)
a[c(1,2),] <- a[c(2,1),]
a
setwd("D:/!!Research/rgee_test/GEE_LPC")
knitr::opts_chunk$set(echo = TRUE)
###ee_install()
library(rgee)
library(rgeeExtra)
library(reticulate)
# Initialize Earth Engine and GD
#ee_Initialize()
ee_Initialize(drive=TRUE)
# Initialize Earth Engine and GD
ee_Authenticate()
4/1AfJohXljf08kVSeeZrI2A6dt-sKcYHcX1jPzoQQ_IKTe27aebcOsLYtXU3s
# Initialize Earth Engine and GD
# ee_Authenticate()
#ee_Initialize()
ee_Initialize(drive=TRUE)
library(sf)
library(sp)
library(geojsonsf)
library(rlist)
# read in each geojson
files_list <- list.files(path="C:/Users/Justin/Desktop/mesquite/mesq_jsons")
# creating a path for each item in a file
file_address_func <- function(file_given) {
addresses <- list()
for (file in file_given) {
address <- "C:/Users/Justin/Desktop/mesquite/mesq_jsons/"
full_address <- paste0(address, file)
length_list <- length(addresses)
addresses <- append(addresses, full_address, after = length_list)
}
return(addresses)
}
listy <- file_address_func(files_list)
#listy
# generating names for each object to assign an sf value
object_names <- function(given_list) {
ob_list <- list()
for (listicle in given_list) {
temp_string <- "buff"
ob_name <- paste0(listicle, temp_string)
length_list <- length(ob_list)
ob_list <- append(ob_list, ob_name, after = length_list)
}
return(ob_list)
}
ob_names <- object_names(files_list)
#ob_names
# creating a function to save all the geojsons to sf objects
rng <- 1:length(listy)
geo_json_func <- function(given_list, given_range) {
json_sf_list <- list()
for (item in given_range) {
full_address <- given_list[[item]]
len_list <- length(json_sf_list)
json_sf_list <- append(json_sf_list, geojson_sf(full_address), after = length(json_sf_list))
}
return(json_sf_list)
}
json_list <- geo_json_func(listy, rng)
json_list[[1]]
# adding sf objects as ee assets
ee_list_func <- function(given_json_list, given_range) {
eeItemList <- list()
for (item in given_range) {
eeItemList <- append(eeItemList,
sf_as_ee(
x = json_list[[item]],
assetID = ob_names[[item]]
),
after = length(eeItemList)
)
}
return(eeItemList)
}
eeItemList <- ee_list_func(json_list, rng)
#eeItemList
### change the feature collection to your boundary asset location
shp <- eeItemList[[2]] # change per buffer ########### currently standardizing. currently
#Have downloaded 1, 5, 7, 10, 17, 18, 24, 29, 30, 31, 32, 33, 36, 39, 43, and 45 for testing
### choose your imagery and the dates for it
year <- ee$ImageCollection('USDA/NAIP/DOQQ') %>%
ee$ImageCollection$filterDate(ee$Date('2016-01-01'),
ee$Date('2016-12-31')) %>%
ee$ImageCollection$filterBounds(shp)
# mosaic the collection into a single image
year <- year$mosaic()
### clipping to shape
clip <- year$clip(shp)
###
### visibility parameters for the color image
visParam <- list(bands <- c('R', 'G', 'B'),
gamma = 1
)
# centering and adding to map to check that it's visualizing properly
#Map$centerObject(shp)
#Map$addLayer(clip, visParams= visParam)
rgb_savi <- function(image_given) {
image_bands <- image_given$select(c("R", "N"))
image <- image_bands
savi <- image$expression(
expression = '(1 + 0.6) * (N - R) / (N + R + 0.6)',
opt_map =  list(
'R' = image$select('R'),
'N' = image$select('N')
)
)$rename('savi')
return(savi)
}
savi <- rgb_savi(clip)
#Map$addLayer(savi)
# adding savi as a band to use
clip <- clip$addBands(savi)
# checking was added
#band_names <- standardized$bandNames()
#print(band_names$get(4)$getInfo())
rgb_endvi <- function(image_given) {
image_bands <- image_given$select(c("N", "G", "B"))
image <- image_bands
endvi <- image$expression(
expression = '((N + G) - (2 * B)) / ((N + G) + (2 + B))',
opt_map =  list(
'N' = image$select('N'),
'G' = image$select('G'),
'B' = image$select('B')
)
)$rename('endvi')
return(endvi)
}
endvi <- rgb_endvi(clip)
# adding endvi as a band to use
clip <- clip$addBands(endvi)
# checking was added
band_names <- clip$bandNames()
#print(band_names$get(5)$getInfo())
print(band_names$get(5)$getInfo())
print(band_names$get(4)$getInfo())
image_st <- clip
st_bandNames <- image_st$bandNames()
meanDict <- image_st$reduceRegion(
reducer = ee$Reducer$mean(),
geometry = shp,
scale = 1,
maxPixels = 200000000,
bestEffort = TRUE,
tileScale = 16
)
means <- ee$Image$constant(meanDict$values(st_bandNames))
centered <- image_st$subtract(means)
stdDevDict <- image_st$reduceRegion(
reducer = ee$Reducer$stdDev(),
geometry = shp,
scale = 1,
maxPixels = 200000000,
bestEffort = TRUE,
tileScale = 16
)
stddevs <- ee$Image$constant(stdDevDict$values(st_bandNames))
standardized <- centered$divide(stddevs)
visParam_st <- list(bands <- c('N', 'R', 'G'),
min = -1,
max = 2,
gamma = 1.2
)
#Map$addLayer(standardized, visParams = visParam_st)
### gaussian smoothing
gaussianKernel <- ee$Kernel$gaussian(
radius = 3,
units = 'pixels'
)
gaussian_smooth <- standardized$convolve(gaussianKernel)
#visParamGauss <- list(bands <- c('R', 'G', 'B'),
#  min= 0,
#  max= 255
#  )
### checking that image was smoothed
#Map$addLayer(gauss, visParams = visParamGauss)
### DoG sharpening
fat <- ee$Kernel$gaussian(
radius = 3,
sigma = 3,
magnitude = -1.0,
units = 'pixels'
)
skinny <- ee$Kernel$gaussian(
radius = 3,
sigma = 0.5,
units = 'pixels'
)
dog <- fat$add(skinny)
gauss <- gaussian_smooth$add(standardized$convolve(dog)) #changed name from sharpened
### creating training samples for the unsupervised classification
training <- gauss$sample(
region = shp,
scale = 1, #change depending on year
numPixels = 10000
)
###
### the actual classification function
clusterer <- ee$Clusterer$wekaXMeans(maxClusters = 10, maxIterations = 5, useKD = TRUE) %>% # change clusters depending on imagery ### check accuracies
ee$Clusterer$train(training)
result <- gauss$cluster(clusterer)
###
### creating a landcover palette to view the result
landcoverPalette <- c(
'#00a944',
'#d6d6d6',
'#c65b8d',
'#000000',
'#ff3434',
'#5bb48f',
'#47f37c',
'#c04848',
'#ded132',
'#5bb48f',
'#0f0077',
'#778bff',
'#8f8f8f',
'#000000',
'#d9a300'
)
visPalette <- list(
min= 0,
max= 9, # change depending on number of clusters
palette = landcoverPalette
)
###
### adding maps to compare
classified <- Map$addLayer(result, visParams = visPalette)
imageryMap <- Map$addLayer(standardized, visParams= visParam_st)
###
### showing the maps
classified | imageryMap
imageryMap <- Map$addLayer(clip, visParams= visParam_st)
### showing the maps
classified | imageryMap
imageryMap <- Map$addLayer(clip, visParams= visParam)
### showing the maps
classified | imageryMap
segmented <- ee$Algorithms$Image$Segmentation$SNIC(gauss)
Map$addLayer(segmented, visParams = visParam)
Map$addLayer(segmented)
### creating training samples for the unsupervised classification
training <- segmented$sample(
region = shp,
scale = 1, #change depending on year
numPixels = 10000
)
###
### the actual classification function
clusterer <- ee$Clusterer$wekaXMeans(maxClusters = 12, maxIterations = 5, useKD = TRUE) %>% # change clusters depending on imagery ### check accuracies
ee$Clusterer$train(training)
result <- segmented$cluster(clusterer)
###
### creating a landcover palette to view the result
landcoverPalette <- c(
'#00a944',
'#d6d6d6',
'#c65b8d',
'#000000',
'#ff3434',
'#5bb48f',
'#47f37c',
'#c04848',
'#ded132',
'#5bb48f',
'#0f0077',
'#778bff',
'#8f8f8f',
'#000000',
'#d9a300'
)
visPalette <- list(
min= 0,
max= 9, # change depending on number of clusters
palette = landcoverPalette
)
###
### adding maps to compare
classified <- Map$addLayer(result, visParams = visPalette)
imageryMap <- Map$addLayer(clip, visParams= visParam)
###
### showing the maps
classified | imageryMap
