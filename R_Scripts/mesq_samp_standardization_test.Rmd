---
title: "mesq_samp_naip"
author: "Justin Dawsey"
date: "2023-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
###ee_install()

library(rgee)
library(rgeeExtra)
library(reticulate)

# Initialize Earth Engine and GD
#ee_Initialize()
ee_Initialize(drive=TRUE)

```

```{r}
library(sf)
library(sp)
library(geojsonsf)
library(rlist)
# read in each geojson


files_list <- list.files(path="C:/Users/Justin/Desktop/mesquite/mesq_jsons")

# creating a path for each item in a file
file_address_func <- function(file_given) {
  addresses <- list()
  
  for (file in file_given) {
    address <- "C:/Users/Justin/Desktop/mesquite/mesq_jsons/"
    full_address <- paste0(address, file)
    length_list <- length(addresses)
    addresses <- append(addresses, full_address, after = length_list)
  }
  return(addresses)
}

listy <- file_address_func(files_list)
#listy
```


```{r}
# generating names for each object to assign an sf value
object_names <- function(given_list) {
  ob_list <- list()
  
  for (listicle in given_list) {
    temp_string <- "buff"
    ob_name <- paste0(listicle, temp_string)
    length_list <- length(ob_list)
    ob_list <- append(ob_list, ob_name, after = length_list)
    
  }
  return(ob_list)
}

ob_names <- object_names(files_list)
#ob_names
```



```{r}
# creating a function to save all the geojsons to sf objects
rng <- 1:length(listy)
geo_json_func <- function(given_list, given_range) {
  json_sf_list <- list()
  
  for (item in given_range) {
    full_address <- given_list[[item]]
    len_list <- length(json_sf_list)
    json_sf_list <- append(json_sf_list, geojson_sf(full_address), after = length(json_sf_list))
  }
  return(json_sf_list)
}  
json_list <- geo_json_func(listy, rng)
json_list[[1]]


# adding sf objects as ee assets
ee_list_func <- function(given_json_list, given_range) {
  eeItemList <- list()
  
  for (item in given_range) {
    eeItemList <- append(eeItemList,
                         sf_as_ee(
                           x = json_list[[item]],
                           assetID = ob_names[[item]]
                         ),
                         after = length(eeItemList)
                         )
    
  }
  return(eeItemList)
}

eeItemList <- ee_list_func(json_list, rng)
#eeItemList

```
# ###############################################
# ###############################################
# ###############################################
# ###############################################
# ###############################################

Loading the NAIP Imagery

Years - NM - 2009 (1m RGB), 2011 (1m), 2014 (1m), 2016 (1m), 2018, 2020, 2022
      - TX - 2004 (1m NRG), 2008 (1m NRG), 2010 (1m) , 2012 (1m), 2014 (1m), 2016 (1m), 2018, 2020, 2022

```{r}
### change the feature collection to your boundary asset location
shp <- eeItemList[[]] # change per buffer ########### currently standardizing. currently 
#Have downloaded 1, 5, 7, 10, 17, 18, 24, 29, 30, 31, 32, 33, 36, 39, 43, and 45 for testing

### choose your imagery and the dates for it
year <- ee$ImageCollection('USDA/NAIP/DOQQ') %>%
      ee$ImageCollection$filterDate(ee$Date('2016-01-01'), 
                                    ee$Date('2016-12-31')) %>%
      ee$ImageCollection$filterBounds(shp)

# mosaic the collection into a single image
year <- year$mosaic()

### clipping to shape
clip <- year$clip(shp)
###

### visibility parameters for the color image
visParam <- list(bands <- c('R', 'G', 'B'),
  gamma = 1
  )

# centering and adding to map to check that it's visualizing properly
#Map$centerObject(shp)
#Map$addLayer(clip, visParams= visParam)
```

Standardization

```{r}
image_st <- clip
st_bandNames <- image_st$bandNames()
meanDict <- image_st$reduceRegion(
  reducer = ee$Reducer$mean(),
  geometry = shp,
  scale = 1,
  maxPixels = 200000000,
  bestEffort = TRUE,
  tileScale = 16
)
means <- ee$Image$constant(meanDict$values(st_bandNames))
centered <- image_st$subtract(means)

stdDevDict <- image_st$reduceRegion(
  reducer = ee$Reducer$stdDev(),
  geometry = shp,
  scale = 1,
  maxPixels = 200000000,
  bestEffort = TRUE,
  tileScale = 16
)

stddevs <- ee$Image$constant(stdDevDict$values(st_bandNames))
standardized <- centered$divide(stddevs)

visParam_st <- list(bands <- c('N', 'R', 'G'),
                    min = -1,
                    max = 2,
                    gamma = 1.2
                    )
#Map$addLayer(standardized, visParams = visParam_st)

```

Adding indices for additional possible accuracy

SAVI (Soil Adjusted Vegetation Index):
SAVI = (1 + L) * (Bnir - Bred) / (Bnir + Bred + L)
--- L = correction factor (0 = high veg, 1 = very little veg)

```{r}
rgb_savi <- function(image_given) {
  image_bands <- image_given$select(c("R", "N"))
  image <- image_bands
  
  savi <- image$expression(
    expression = '(1 + 0.6) * (N - R) / (N + R + 0.6)',
    opt_map =  list(
        'R' = image$select('R'),
        'N' = image$select('N')
        )
    )$rename('savi')
  return(savi)
}

savi <- rgb_savi(standardized)
#Map$addLayer(savi)

# adding savi as a band to use
standardized <- standardized$addBands(savi)

# checking was added
#band_names <- standardized$bandNames()
#print(band_names$get(4)$getInfo()) 
```

ENDVI (Enhanced Normalized Difference Vegetation Index):
ENDVI = ((NIR + Green) - (2 * Blue)) / ((NIR + Green) + (2 * Blue))

```{r}
rgb_endvi <- function(image_given) {
  image_bands <- image_given$select(c("N", "G", "B"))
  image <- image_bands
  
  endvi <- image$expression(
    expression = '((N + G) - (2 * B)) / ((N + G) + (2 + B))',
    opt_map =  list(
        'N' = image$select('N'),  
        'G' = image$select('G'),
        'B' = image$select('B')
        )
    )$rename('endvi')
  return(endvi)
}

endvi <- rgb_endvi(standardized)

# adding endvi as a band to use
standardized <- standardized$addBands(endvi)

# checking was added
band_names <- standardized$bandNames()
#print(band_names$get(5)$getInfo()) 
```

Sharpening and smoothing

```{r}
### DoG sharpening
fat <- ee$Kernel$gaussian(
  radius = 3,
  sigma = 3,
  magnitude = -1.0,
  units = 'pixels'
)

skinny <- ee$Kernel$gaussian(
  radius = 3,
  sigma = 0.5,
  units = 'pixels'
)

dog <- fat$add(skinny)
gauss <- standardized$add(standardized$convolve(dog)) #changed name from sharpened


### gaussian smoothing
#gaussianKernel <- ee$Kernel$gaussian(
#  radius = 3,
#  units = 'pixels'
#)

#gauss <- sharpened$convolve(gaussianKernel)


#visParamGauss <- list(bands <- c('R', 'G', 'B'),
#  min= 0,
#  max= 255
#  )

### checking that image was smoothed
#Map$addLayer(gauss, visParams = visParamGauss)
```

Training the classification algorithm and showing the display parameters

```{r}

### creating training samples for the unsupervised classification
training <- gauss$sample(
  region = shp,
  scale = 1, #change depending on year
  numPixels = 10000
)
###

### the actual classification function
clusterer <- ee$Clusterer$wekaXMeans(maxClusters = 10, maxIterations = 5, useKD = TRUE) %>% # change clusters depending on imagery ### check accuracies
  ee$Clusterer$train(training)

result <- gauss$cluster(clusterer)
###

### creating a landcover palette to view the result
landcoverPalette <- c(
  '#00a944', 
  '#d6d6d6', 
  '#c65b8d', 
  '#000000', 
  '#ff3434', 
  '#5bb48f', 
  '#47f37c', 
  '#c04848', 
  '#ded132', 
  '#5bb48f', 
  '#0f0077', 
  '#778bff',
  '#8f8f8f',
  '#000000',
  '#d9a300'
  
)

visPalette <- list(
  min= 0,
  max= 9, # change depending on number of clusters
  palette = landcoverPalette
  )
###

### adding maps to compare
#classified <- Map$addLayer(result, visParams = visPalette)
#imageryMap <- Map$addLayer(standardized, visParams= visParam_st)
###
```

Displaying the maps

```{r}
### showing the maps
classified | imageryMap
```

It may be worth just going ahead and making some training samples for each of the cover types I want to train for. That way a confusion matrix can automatically be generated.


```{r}
drive_image <- ee_image_to_drive(
  image = gauss,
  description = "export",
  folder = "!imagery",
  region = shp,
  scale = 1,
  max = 130000000
)

drive_image$start()
```


Downloading the classified map

```{r}
#shp_geo <- shp$geometry()

drive_image <- ee_image_to_drive(
  image = result,
  description = "export",
  folder = "!imagery",
  region = shp,
  scale = 1,
  max = 130000000
)

drive_image$start()
```

If exporting to r
```{r}
naipNM_2009 <- ee_as_raster( #change name depending on raster to be downloaded
  image = result,
  region = shp_geo,
  dsn = "naipNM_2009.tif", # change for your own path.
  scale = 1,
)
```
