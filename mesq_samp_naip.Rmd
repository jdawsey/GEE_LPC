---
title: "gee_javascript_test"
author: "Justin Dawsey"
date: "2023-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
###ee_install()

library(rgee)
library(rgeeExtra)
library(reticulate)

# Initialize Earth Engine and GD
ee_Initialize(drive=TRUE)

```


```{r}

#Example
landsat <- ee$Image('LANDSAT/LT04/C01/T1/LT04_008067_19890917')

visParam <- list(bands <- c('B5', 'B4', 'B3'),
  min= 0,
  max= 128,
  gamma = c(0.95, 1.1, 1)
  )

Map$setCenter(lon=-77.20, lat=-9.85, zoom=10)
m1 <- Map$addLayer(landsat, visParams= visParam, name="SRTM", shown=TRUE)

m1
```



```{r}
library(sf)
library(sp)
library(geojsonsf)
# read in each geojson


files_list <- list.files(path="C:/Users/Justin/Desktop/mesquite/mesq_jsons")

geo_json_func <- function(file_given) {
  sf_objects <- list()
  
  for (file in file_given) {
    append(sf_objects, st_read(system.file(dsn = file, package = "geojsonsf")))
  }
  return(sf_objects)
}

geo_json_func <- function(file_given) {
  sf_objects <- list()
  
  for (file in file_given) {
    address <- "C:/Users/Justin/Desktop/mesquite/mesq_jsons/"
    full_address <- paste(address, file)
    #temp_string <- "buff"
    #address <- geojson_sf(full_address)
    append(sf_objects, full_address)
  }
  return(sf_objects)
}

listy <- geo_json_func(files_list)
listy

buff_a <- geojson_sf("C:/Users/Justin/Desktop/mesquite/mesq_jsons/a.geojson")

#buff_a <- read_sf(dsn = "C:/Users/Justin/Desktop/mesquite/mesq_shps", layer = "a") %>%
  


```

Loading the NAIP Imagery

Years - NM - 2009 (1m RGB), 2011 (1m), 2014 (1m), 2016 (1m), 2018, 2020, 2022
      - TX - 2004 (1m NRG), 2008 (1m NRG), 2010 (1m) , 2012 (1m), 2014 (1m), 2016 (1m), 2018, 2020, 2022

```{r}
### change the feature collection to your boundary asset location
#shp <- ee$FeatureCollection('users/jdawsey/assets/20km_nm')
shp <- buff_a

### choose your imagery and the dates for it
year <- ee$ImageCollection('USDA/NAIP/DOQQ') %>%
      ee$ImageCollection$filterDate(ee$Date('2014-01-01'), 
                                    ee$Date('2014-12-31')) %>%
      ee$ImageCollection$filterBounds(shp)

# mosaic the collection into a single image
year <- year$mosaic()

### clipping to shape
clip <- year$clip(shp)
###

### visibility parameters for the color image
visParam <- list(bands <- c('R', 'G', 'B'),
  gamma = 1
  )

# centering and adding to map to check that it's visualizing properly
Map$centerObject(shp)
Map$addLayer(clip, visParams= visParam)
```

Normalization

```{r}
#setting up to normalize -- doesn't work yet
# Get mean and SD in every band by combining reducers.
stats <- clip$reduceRegion(
  reducer = ee$Reducer$mean()$combine(
    reducer2 = ee$Reducer$stdDev(),
    sharedInputs = TRUE
  ),
  geometry = shp,
  scale = 1, # change depending on year
  bestEffort = TRUE # Use maxPixels if you care about scale.
)

#print(stats$getInfo())

# Extract means and SDs to images.
meansImage <- stats$toImage()$select('.*_mean')
sdsImage <- stats$toImage()$select('.*_stdDev')
coeffVarImage <- meansImage$divide(sdsImage)

normalized = clip$subtract(coeffVarImage)


######## Visualize if wanted ################
#visParamNorm <- list(bands <- c('R', 'G', 'B'),
#  min= 0,
#  max= 255
#  )

# Map$addLayer(normalized, visParams = visParamNorm)
###
```

Adding indices for additional possible accuracy

https://isprs-archives.copernicus.org/articles/XLII-3/1215/2018/isprs-archives-XLII-3-1215-2018.pdf
EVALUATION OF RGB-BASED VEGETATION INDICES FROM UAV IMAGERY TO
ESTIMATE FORAGE YIELD IN GRASSLAND

VARI (Visible Atmospherically Resistant Index):
Gitelson AA, Vina A, Arkebauer TJ, Rundquist DC, Keydan G, Leavitt B. Remote estimation of leaf area index and green leaf biomass in maize canopies. Geophys Res Lett. 2003;30(30):335â€“43. https://doi.org/10.1029/2002gl016450.

```{r}
#Doesn't work for NM 2009 -- see "check bands"
#band_names <- normalized$bandNames()
#print(band_names$get(4)$getInfo())

rgb_vari <- function(image_given) {
  image_bands <- image_given$select(c("R", "G", "B"))
  image <- image_bands
  
  vari <- image$expression(
    expression = '(G - R) / (G + R - B)',
    opt_map =  list(
        'G' = image$select('G'),
        'R' = image$select('R'),
        'B' = image$select('B')
        )
    )$rename('vari')
  return(vari)
}

vari <- rgb_vari(normalized)

# adding vari as a band to use
normalized <- normalized$addBands(vari)

# checking was added
band_names <- normalized$bandNames()
print(band_names$get(4)$getInfo()) 
```

SAVI (Soil Adjusted Vegetation Index):
SAVI = (1 + L) * (Bnir - Bred) / (Bnir + Bred + L)
--- L = correction factor (0 = high veg, 1 = very little veg)

```{r}
rgb_savi <- function(image_given) {
  image_bands <- image_given$select(c("R", "N"))
  image <- image_bands
  
  savi <- image$expression(
    expression = '(1 + 0.6) * (N - R) / (N + R + 0.6)',
    opt_map =  list(
        'R' = image$select('R'),
        'N' = image$select('N')
        )
    )$rename('savi')
  return(savi)
}

savi <- rgb_savi(normalized)

# adding savi as a band to use
normalized <- normalized$addBands(savi)

# checking was added
band_names <- normalized$bandNames()
print(band_names$get(5)$getInfo()) 
```

ENDVI (Enhanced Normalized Difference Vegetation Index):
ENDVI = ((NIR + Green) - (2 * Blue)) / ((NIR + Green) + (2 * Blue))

```{r}
rgb_endvi <- function(image_given) {
  image_bands <- image_given$select(c("N", "G", "B"))
  image <- image_bands
  
  endvi <- image$expression(
    expression = '((N + G) - (2 * B)) / ((N + G) + (2 + B))',
    opt_map =  list(
        'N' = image$select('N'),  
        'G' = image$select('G'),
        'B' = image$select('B')
        )
    )$rename('endvi')
  return(endvi)
}

endvi <- rgb_endvi(normalized)

# adding endvi as a band to use
normalized <- normalized$addBands(endvi)

# checking was added
band_names <- normalized$bandNames()
print(band_names$get(6)$getInfo()) 
```

Running a correlation test on the bands and indices. May be worth running a PCA analysis.

```{r}
# not needed for naip imagery without NIR band

```

Re-normalizing

```{r}
# Get mean and SD in every band by combining reducers.
stats <- normalized$reduceRegion(
  reducer = ee$Reducer$mean()$combine(
    reducer2 = ee$Reducer$stdDev(),
    sharedInputs = TRUE
  ),
  geometry = shp,
  scale = 1, # change depending on year
  bestEffort = TRUE # Use maxPixels if you care about scale.
)

#print(stats$getInfo())

# Extract means and SDs to images.
meansImage <- stats$toImage()$select('.*_mean')
sdsImage <- stats$toImage()$select('.*_stdDev')
coeffVarImage <- meansImage$divide(sdsImage)

normalized = normalized$subtract(coeffVarImage)
```

Sharpening and smoothing

```{r}
### DoG sharpening
fat <- ee$Kernel$gaussian(
  radius = 3,
  sigma = 3,
  magnitude = -1.0,
  units = 'pixels'
)

skinny <- ee$Kernel$gaussian(
  radius = 3,
  sigma = 0.5,
  units = 'pixels'
)

dog <- fat$add(skinny)
sharpened <- normalized$add(normalized$convolve(dog))
###

### gaussian smoothing
gaussianKernel <- ee$Kernel$gaussian(
  radius = 3,
  units = 'pixels'
)

gauss <- sharpened$convolve(gaussianKernel)
###

visParamGauss <- list(bands <- c('R', 'G', 'B'),
  min= 0,
  max= 255
  )

### checking that image was smoothed
#Map$addLayer(gauss, visParams = visParamGauss)
```

Training the classification algorithm and showing the display parameters

```{r}

### creating training samples for the unsupervised classification
training <- gauss$sample(
  region = shp,
  scale = 1, #change depending on year
  numPixels = 5000
)
###

### the actual classification function
clusterer <- ee$Clusterer$wekaKMeans(15) %>% # change clusters depending on imagery
  ee$Clusterer$train(training)

result <- gauss$cluster(clusterer)
###

### creating a landcover palette to view the result
landcoverPalette <- c(
  '#00a944', 
  '#d6d6d6', 
  '#c65b8d', 
  '#ded132', 
  '#ff3434', 
  '#5bb48f', 
  '#47f37c', 
  '#c04848', 
  '#ded132', 
  '#5bb48f', 
  '#0f0077', 
  '#778bff',
  '#8f8f8f',
  '#000000',
  '#d9a300'
  
)

visPalette <- list(
  min= 0,
  max= 14, # change depending on number of clusters
  palette = landcoverPalette
  )
###

### adding maps to compare
classified <- Map$addLayer(result, visParams = visPalette)
imageryMap <- Map$addLayer(clip, visParams= visParam)
###
```

Displaying the maps

```{r}
### showing the maps
classified | imageryMap
```

It may be worth just going ahead and making some training samples for each of the cover types I want to train for. That way a confusion matrix can automatically be generated.


Downloading the classified map

```{r}
shp_geo <- shp$geometry()

drive_image <- ee_image_to_drive(
  image = result,
  description = "export",
  folder = "!imagery",
  region = shp_geo,
  scale = 1,
  maxPixels = 155232114715
)

drive_image$start()
```

If exporting to r
```{r}
naipNM_2009 <- ee_as_raster( #change name depending on raster to be downloaded
  image = result,
  region = shp_geo,
  dsn = "naipNM_2009.tif", # change for your own path.
  scale = 1,
  maxPixels = 155232114715
)
```
